On the NameNode, format the file system, then start HDFS.

$ hdfs namenode -format
$ $HADOOP_HOME/sbin/start-dfs.sh
Start YARN:

$ $HADOOP_HOME/sbin/start-yarn.sh
Start the job history server:

$ $HADOOP_HOME/sbin/mr-jobhistory-daemon.sh start historyserver
To see the Java processes (Hadoop daemons for instance), enter

$ jps
Create a home directory on HDFS

$ hdfs dfs -mkdir /user
$ hdfs dfs -mkdir /user/ubuntu
Create random data for the Terasort example,

$ hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar teragen 500000 random-data
Sort random data,

$ hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar terasort random-data sorted-data
Write files to disk with TestDFSIO:

$ hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-*-tests.jar TestDFSIO -write -nrFiles 10 -fileSize 5MB
Read files from disk with TestDFSIO:

$ hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-*-tests.jar TestDFSIO -read -nrFiles 10 -fileSize 5MB
